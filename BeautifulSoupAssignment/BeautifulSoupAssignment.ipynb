{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9723614c-41e8-4943-b9be-e10b4de61fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#1. Write a python program to display IMDB’s Top rated 100 Indian movies’ data\n",
    "# https://www.imdb.com/list/ls056092300/ (i.e. name, rating, year ofrelease) and make data frame.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'http://www.imdb.com/list/ls056092300/'\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "movies = soup.find_all('div', class_='lister-item-content')\n",
    "\n",
    "movie_list = []\n",
    "\n",
    "for movie in movies:\n",
    "    name = movie.h3.a.text\n",
    "    rating = movie.find('span', class_='ipl-rating-star__rating').text\n",
    "    year = movie.find('span', class_='lister-item-year').text.strip('()')\n",
    "\n",
    "    movie_list.append({'Name': name, 'Rating': rating, 'Year': year})\n",
    "\n",
    "df = pd.DataFrame(movie_list)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "38b9257f-c9b2-4321-9240-7ec80873a188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No posts found. The structure of the website may have changed or content is not available in static HTML.\n"
     ]
    }
   ],
   "source": [
    "# 2) Write a python program to scrape details of all the posts from https://www.patreon.com/coreyms .Scrape the\n",
    "#heading, date, content and the likes for the video from the link for the youtube video from the post.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the Patreon page\n",
    "url = 'https://www.patreon.com/coreyms'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find all post containers (update based on actual HTML)\n",
    "    post_containers = soup.find_all('article')  # Use actual tag/class from inspection\n",
    "\n",
    "    if not post_containers:\n",
    "        print(\"No posts found. The structure of the website may have changed or content is not available in static HTML.\")\n",
    "    else:\n",
    "        for post in post_containers:\n",
    "            try:\n",
    "                # Extract the heading\n",
    "                heading = post.find('h1')  # Update with actual tag/class if necessary\n",
    "                heading = heading.text.strip() if heading else 'No heading available'\n",
    "                \n",
    "                # Extract the date\n",
    "                date = post.find('time')  # Update with actual tag/class if necessary\n",
    "                date = date.text.strip() if date else 'No date available'\n",
    "\n",
    "                # Extract the content\n",
    "                content = post.find('div', class_='content')  # Update with actual class if necessary\n",
    "                content = content.text.strip() if content else 'No content available'\n",
    "\n",
    "                # Extract the likes (if available)\n",
    "                likes = post.find('span', class_='likes')  # Update with actual class if necessary\n",
    "                likes = likes.text.strip() if likes else 'No likes available'\n",
    "                \n",
    "                # Extract the YouTube link (if available)\n",
    "                youtube_link = post.find('a', href=True, text='YouTube')  # Adjust selector based on actual HTML\n",
    "                youtube_link = youtube_link['href'] if youtube_link else 'No YouTube link available'\n",
    "\n",
    "                # Print the details\n",
    "                print(f\"Heading: {heading}\")\n",
    "                print(f\"Date: {date}\")\n",
    "                print(f\"Content: {content}\")\n",
    "                print(f\"Likes: {likes}\")\n",
    "                print(f\"YouTube Link: {youtube_link}\")\n",
    "                print(\"-\" * 40)\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting data: {e}\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "91a19964-12ae-4786-a4e5-aacec969cfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for Indira Nagar...\n",
      "No data found for locality: Indira Nagar\n",
      "Fetching data for Jayanagar...\n",
      "No data found for locality: Jayanagar\n",
      "Fetching data for Rajaji Nagar...\n",
      "No data found for locality: Rajaji Nagar\n"
     ]
    }
   ],
   "source": [
    "#3) Write a python program to scrape house details from mentioned URL. It should include house title, location,\n",
    "#area, EMI and price from https://www.nobroker.in/ .Enter three localities which are Indira Nagar, Jayanagar,\n",
    "#Rajaji Nagar\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fetch_house_details(locality):\n",
    "    url = f'https://www.nobroker.in/property/sale/bangalore/{locality.replace(\" \", \"-\")}'\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    houses = soup.find_all('div', class_='card')\n",
    "\n",
    "    if not houses:\n",
    "        print(f\"No data found for locality: {locality}\")\n",
    "        return\n",
    "\n",
    "    for house in houses:\n",
    "        try:\n",
    "            title = house.find('h2', class_='heading-6').get_text(strip=True)\n",
    "        except:\n",
    "            title = 'Title not available'\n",
    "\n",
    "        try:\n",
    "            location = house.find('div', class_='flex-4').get_text(strip=True)\n",
    "        except:\n",
    "            location = 'Location not available'\n",
    "\n",
    "        try:\n",
    "            area = house.find('div', class_='area').get_text(strip=True)\n",
    "        except:\n",
    "            area = 'Area not available'\n",
    "\n",
    "        try:\n",
    "            emi = house.find('div', class_='emi').get_text(strip=True)\n",
    "        except:\n",
    "            emi = 'EMI not available'\n",
    "\n",
    "        try:\n",
    "            price = house.find('div', class_='price').get_text(strip=True)\n",
    "        except:\n",
    "            price = 'Price not available'\n",
    "\n",
    "        print(f\"Title: {title}\")\n",
    "        print(f\"Location: {location}\")\n",
    "        print(f\"Area: {area}\")\n",
    "        print(f\"EMI: {emi}\")\n",
    "        print(f\"Price: {price}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "localities = ['Indira Nagar', 'Jayanagar', 'Rajaji Nagar']\n",
    "\n",
    "for locality in localities:\n",
    "    print(f\"Fetching data for {locality}...\")\n",
    "    fetch_house_details(locality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db408ef3-73a6-48ac-b2e5-16bfc3af6e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'bewakoof x dc', 'Price': 'Price not available', 'Image URL': 'https://images.bewakoof.com/t640/men-s-black-adam-graphic-printed-t-shirt-541266-1709214736-1.jpg'}\n",
      "{'Name': 'bewakoof x house of the dragon', 'Price': 'Price not available', 'Image URL': 'https://images.bewakoof.com/t640/men-s-black-house-of-the-dragon-iconic-graphic-printed-t-shirt-519411-1715257899-1.jpg'}\n",
      "{'Name': 'Bewakoof®', 'Price': 'Price not available', 'Image URL': 'https://images.bewakoof.com/t640/men-s-black-warriors-graphic-printed-oversized-t-shirt-519149-1715257507-1.jpg'}\n",
      "{'Name': 'bewakoof x tom & jerry', 'Price': 'Price not available', 'Image URL': 'https://images.bewakoof.com/t640/women-s-blue-moody-jerry-graphic-printed-oversized-t-shirt-585902-1715257595-1.jpg'}\n",
      "{'Name': 'Bewakoof®', 'Price': 'Price not available', 'Image URL': 'https://images.bewakoof.com/t640/women-aop-oversize-t-shirt-12-580375-1684862463-1.jpg'}\n",
      "{'Name': 'Bewakoof®', 'Price': 'Price not available', 'Image URL': 'https://images.bewakoof.com/t640/men-s-sun-kissed-green-t-shirt-315189-1679049039-1.jpg'}\n",
      "{'Name': 'bewakoof x marvel', 'Price': 'Price not available', 'Image URL': 'https://images.bewakoof.com/t640/men-s-green-wakanda-forever-graphic-printed-oversized-t-shirt-637169-1721201559-1.jpg'}\n",
      "{'Name': 'bewakoof x rick and morty', 'Price': 'Price not available', 'Image URL': 'https://images.bewakoof.com/t640/men-s-green-stoned-rick-morty-graphic-printed-oversized-t-shirt-605040-1717578801-1.jpg'}\n",
      "{'Name': 'bewakoof x tom & jerry', 'Price': 'Price not available', 'Image URL': 'https://images.bewakoof.com/t640/women-s-green-weirdos-forever-graphic-printed-oversized-t-shirt-592030-1707292567-1.jpg'}\n",
      "{'Name': 'Bewakoof®', 'Price': 'Price not available', 'Image URL': 'https://images.bewakoof.com/t640/women-s-black-tropical-vibes-typography-oversized-t-shirt-493433-1715257753-1.jpg'}\n"
     ]
    }
   ],
   "source": [
    "#4) Write a python program to scrape first 10 product details which include product name , price , Image URL from\n",
    "# https://www.bewakoof.com/bestseller?sort=popular .\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the Bewakoof page\n",
    "url = 'https://www.bewakoof.com/bestseller?sort=popular'\n",
    "\n",
    "# Headers to simulate a real browser request\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all product containers\n",
    "products = soup.find_all('div', class_='productCardBox', limit=10)\n",
    "\n",
    "product_list = []\n",
    "\n",
    "for product in products:\n",
    "    name = product.find('h3').text if product.find('h3') else 'N/A'\n",
    "    price_tag = product.find('span', class_='discountedPriceText')\n",
    "    price = price_tag.text if price_tag else 'Price not available'\n",
    "    image_tag = product.find('img')\n",
    "    image_url = image_tag['src'] if image_tag else 'Image not available'\n",
    "    \n",
    "    product_list.append({'Name': name, 'Price': price, 'Image URL': image_url})\n",
    "\n",
    "# Print the results\n",
    "for item in product_list:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "549476ce-1676-4d37-a40e-171734649684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline: Bull market limps into 2-year birthday with soft economic landing in doubt and stock leaders failing\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/09/07/bull-market-limps-into-2-year-birthday-with-soft-economic-landing-in-doubt-and-stock-leaders-failing.html\n",
      "----------------------------------------\n",
      "Headline: Small nuclear reactors could power the future — the challenge is building the first one in the U.S.\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/09/07/how-small-modular-reactors-could-expand-nuclear-power-in-the-us.html\n",
      "----------------------------------------\n",
      "Headline: The latest jobs report leaves stocks in a tough spot heading into the new week\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/09/06/the-latest-jobs-report-leaves-stocks-in-a-tough-spot-heading-into-the-new-week.html\n",
      "----------------------------------------\n",
      "Headline: Flocking to defensive stocks paid off for investors this week\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/09/06/flocking-to-defensive-stocks-paid-off-for-investors-this-week.html\n",
      "----------------------------------------\n",
      "Headline: Bull market limps into 2-year birthday with soft economic landing in doubt and stock leaders failing\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/09/07/bull-market-limps-into-2-year-birthday-with-soft-economic-landing-in-doubt-and-stock-leaders-failing.html\n",
      "----------------------------------------\n",
      "Headline: This gym stock is a buy because of pickleball surge, says Bank of America\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/09/07/buy-this-gym-stock-because-of-popular-pickleball-says-bank-of-america.html\n",
      "----------------------------------------\n",
      "Headline: Wells Fargo's top picks in September include this tech giant and pharma leader\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/09/07/wells-fargos-top-picks-in-september-include-this-tech-giant-and-pharma-leader.html\n",
      "----------------------------------------\n",
      "Headline: This semiconductor ETF just had its worst week since 2020. Here's what's next\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/09/07/this-semiconductor-etf-smh-just-had-its-worst-week-since-2020.html\n",
      "----------------------------------------\n",
      "Headline: The latest jobs report leaves stocks in a tough spot heading into the new week\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/09/06/the-latest-jobs-report-leaves-stocks-in-a-tough-spot-heading-into-the-new-week.html\n",
      "----------------------------------------\n",
      "Headline: 'Get Britain building again': New UK finance chief restores housing targets\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/07/08/uk-election-2024-rachel-reeves-announces-growth-measures.html\n",
      "----------------------------------------\n",
      "Headline: Britain's Labour pulled off a thumping election victory with just 34% of the national vote\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/07/05/uk-election-2024-britains-labour-pulled-off-a-thumping-election-victory.html\n",
      "----------------------------------------\n",
      "Headline: UK's Labour Party secures landslide victory in general election\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/video/2024/07/05/uks-labour-party-secures-landslide-victory-in-general-election.html\n",
      "----------------------------------------\n",
      "Headline: Labour does not have much headroom in terms of fiscal changes, economist says\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/video/2024/07/05/labour-does-not-have-much-headroom-in-terms-of-fiscal-changes-economist.html\n",
      "----------------------------------------\n",
      "Headline: Outgoing UK PM Rishi Sunak to step down as Conservative Party leader\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/07/05/uk-election-rishi-sunak-to-step-down-as-conservative-party-leader-.html\n",
      "----------------------------------------\n",
      "Headline: World swelters through its hottest summer on record for the second year running\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/09/06/climate-crisis-world-logs-its-hottest-summer-on-record.html\n",
      "----------------------------------------\n",
      "Headline: Water shortages are brewing future wars — with several flashpoints worldwide\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/09/05/water-wars-flashpoints-identified-in-africa-asia-and-the-middle-east.html\n",
      "----------------------------------------\n",
      "Headline: Sweden's Volvo Cars scraps plan to sell only electric vehicles by 2030\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/09/04/swedens-volvo-cars-scraps-plan-to-only-sell-electric-vehicles-by-2030.html\n",
      "----------------------------------------\n",
      "Headline: ESG investors appear to be getting much more comfortable with defense stocks\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/09/02/esg-sustainable-investors-appear-more-comfortable-with-defense-stocks.html\n",
      "----------------------------------------\n",
      "Headline: Finland will soon bury spent nuclear fuel in the world’s first geological tomb\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/08/29/onkalo-finland-to-bury-nuclear-waste-in-worlds-first-geological-tomb.html\n",
      "----------------------------------------\n",
      "Headline: Passengers often ignore in-flight safety videos. But this 'honest' one has 8.4 million views\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/09/05/youtube-video-about-flight-safety-that-airlines-dont-want-you-to-see.html\n",
      "----------------------------------------\n",
      "Headline: Has Boeing shaken your confidence to fly? A new MIT study could restore it\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/09/02/fear-of-flying-a-new-mit-study-shows-flying-gets-safer-by-the-decade.html\n",
      "----------------------------------------\n",
      "Headline: Interest to visit Japan soars, while China struggles to lure travelers back\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/08/27/why-travel-demand-to-visit-china-is-low-but-interest-in-japan-is-high.html\n",
      "----------------------------------------\n",
      "Headline: Can a robot give a decent massage? We tested one at a luxury hotel in NYC\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/08/22/a-robot-that-gives-massages-this-is-what-it-looks-and-feels-like.html\n",
      "----------------------------------------\n",
      "Headline: This ship travels the world full time — here's how much an apartment on it costs\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/08/21/ship-that-travels-the-world-full-time-heres-how-much-it-costs.html\n",
      "----------------------------------------\n",
      "Headline: Divorce parties reached an all-time high last year: It's celebrating 'one of the bravest choices I've ever...\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/09/07/divorce-parties-reached-an-all-time-high-last-year-heres-why.html\n",
      "----------------------------------------\n",
      "Headline: This luxury psilocybin retreat 'creates better leaders,' founders say\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/09/07/this-luxury-psilocybin-retreat-creates-better-leaders-founders-say.html\n",
      "----------------------------------------\n",
      "Headline: Top 2 U.S. cities to retire are in Florida—No. 3 is nearly 1,800 miles away\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/09/07/wallethub-best-us-cities-to-retire.html\n",
      "----------------------------------------\n",
      "Headline: CEO quit his job, bought a snack company for $250K—now it brings in $103M/year\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/09/07/lesserevil-ceo-why-i-left-wall-street-for-a-failing-snack-company.html\n",
      "----------------------------------------\n",
      "Headline: How to master your money: Practical strategies to grow your wealth\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/2024/07/10/achieve-financial-wellness-be-happier-wealthier-and-more-secure.html\n",
      "----------------------------------------\n",
      "Headline: What are the economics of war?\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/video/2024/08/07/what-are-the-economics-of-war.html\n",
      "----------------------------------------\n",
      "Headline: What is the internet of bodies?\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/video/2024/05/31/what-is-the-internet-of-bodies.html\n",
      "----------------------------------------\n",
      "Headline: How the world got into $315 trillion of debt\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/video/2024/05/28/how-the-world-got-into-315-trillion-of-debt.html\n",
      "----------------------------------------\n",
      "Headline: eVTOLS: Are flying cars finally becoming reality?\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/video/2024/03/28/evtols-how-flying-cars-are-becoming-reality.html\n",
      "----------------------------------------\n",
      "Headline: How China's property bubble burst\n",
      "Date: Date not available\n",
      "Link: https://www.cnbc.com/video/2024/02/29/how-chinas-property-bubble-burst.html\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 5) Please visit https://www.cnbc.com/world/?region=world and scrap-\n",
    "# a) headings\n",
    "# b) date\n",
    "# c) News link\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the CNBC World News page\n",
    "url = \"https://www.cnbc.com/world/?region=world\"\n",
    "\n",
    "# Send a GET request to fetch the page content\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the page content with BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all news articles\n",
    "articles = soup.find_all('div', class_='Card-standardBreakerCard')\n",
    "\n",
    "# Loop through each article and extract details\n",
    "for article in articles:\n",
    "    # Extract the headline\n",
    "    headline = article.find('a', class_='Card-title').get_text(strip=True)\n",
    "    \n",
    "    # Extract the link to the article\n",
    "    link = article.find('a', class_='Card-title')['href']\n",
    "    \n",
    "    # Extract the date (if available)\n",
    "    date = article.find('time')\n",
    "    if date:\n",
    "        date = date.get_text(strip=True)\n",
    "    else:\n",
    "        date = 'Date not available'\n",
    "\n",
    "    # Print the details\n",
    "    print(f\"Headline: {headline}\")\n",
    "    print(f\"Date: {date}\")\n",
    "    print(f\"Link: {link}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3391271c-7fbd-4158-bd4d-ee9b485e7794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No papers found. The structure of the website may have changed or content is not available in static HTML.\n"
     ]
    }
   ],
   "source": [
    "# 6) Please visit https://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/most-downloaded-\n",
    "# articles/ and scrap-\n",
    "#a) Paper title\n",
    "#b) date\n",
    "#c) Author\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the KEAI Publishing page\n",
    "url = 'https://www.keaipublishing.com/en/journals/artificial-intelligence-in-agriculture/most-downloaded-articles/'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Adjust the selector based on the actual HTML structure\n",
    "    paper_containers = soup.find_all('div', class_='article-item')  # Update with actual class or tag\n",
    "\n",
    "    if not paper_containers:\n",
    "        print(\"No papers found. The structure of the website may have changed or content is not available in static HTML.\")\n",
    "    else:\n",
    "        for paper in paper_containers:\n",
    "            # Extract the title\n",
    "            title = paper.find('h3', class_='title')  # Update with actual class or tag if necessary\n",
    "            title = title.text.strip() if title else 'No title available'\n",
    "            \n",
    "            # Extract the date\n",
    "            date = paper.find('time', class_='date')  # Update with actual class or tag if necessary\n",
    "            date = date.text.strip() if date else 'No date available'\n",
    "\n",
    "            # Extract authors\n",
    "            authors = paper.find('span', class_='authors')  # Update with actual class or tag if necessary\n",
    "            authors_text = authors.text.strip() if authors else 'No authors available'\n",
    "\n",
    "            # Print the details\n",
    "            print(f\"Paper Title: {title}\")\n",
    "            print(f\"Date: {date}\")\n",
    "            print(f\"Authors: {authors_text}\")\n",
    "            print(\"-\" * 40)\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0131a5e1-b5f0-4d40-b50b-a8014ce9f5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
